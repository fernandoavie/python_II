{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22628b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080cb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data Set\n",
    "\n",
    "df_one = pd.read_csv(\"predictive_maintenance.csv\")\n",
    "df_two = pd.read_csv(\"predictive_maintenance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Data Sets (Same Columns)\n",
    "\n",
    "merged_df = pd.concat([df_one, df_two], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# Merge the Data Sets (Different Columns)\n",
    "\n",
    "# 1) Inner Join\n",
    "merged_df = pd.merge(df_one, df_two, on='key_column')\n",
    "\n",
    "# 2) Left Join\n",
    "merged_df = pd.merge(df_one, df_two, on='key_column', how='left')\n",
    "\n",
    "# 3) Right Join\n",
    "merged_df = pd.merge(df_one, df_two, on='key_column', how='outer')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e404a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical and Categorical Columns\n",
    "\n",
    "numerical_features = list(train_set._get_numeric_data())\n",
    "\n",
    "categorical_features = list(train_set.drop(numerical_features, axis = 1))\n",
    "categorical_features.remove(\"Input here the target variable.\")\n",
    "\n",
    "print(f\"The Numerical Features:\\n {numerical_features}\\n\")\n",
    "print(f\"The Categorical Features:\\n {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616e0e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive Statistics\n",
    "\n",
    "def description(df):\n",
    "    desc = pd.DataFrame(index = list(df))\n",
    "    desc['type'] = df.dtypes\n",
    "    desc['count'] = df.count()\n",
    "    desc['nunique'] = df.nunique()\n",
    "    desc['%unique'] = desc['nunique'] / len(df) * 100\n",
    "    desc['null'] = df.isnull().sum()\n",
    "    desc['%null'] = desc['null'] / len(df) * 100\n",
    "    desc['min'] = df.min()\n",
    "    desc['max'] = df.max()\n",
    "    \n",
    "    return desc\n",
    "\n",
    "merged_df_description = description(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24daf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test Set Separation\n",
    "\n",
    "target_variable = \"Input here the target variable.\"\n",
    "X = merged_df.drop(target_variable, axis=1)\n",
    "y = merged_df[target_variable]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size = 0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb91804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Missing Values\n",
    "\n",
    "# Initialize the imputer\n",
    "# strategy can be \"mean\", \"median\", \"most_frequent\"\n",
    "imputer = SimpleImputer(strategy='mean')  # Or another strategy as needed\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "imputer.fit(X_train)\n",
    "\n",
    "# Transform both the training and the test data\n",
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# If you want to convert the imputed arrays back into DataFrames\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93732458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute Missing Values For Different Data Types\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define the imputer for numerical columns\n",
    "numerical_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Define the imputer for categorical columns\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_imputer, numerical_columns),\n",
    "        ('cat', categorical_imputer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df  # Your input features\n",
    "\n",
    "# Fit and transform the data\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "\n",
    "# If you want to convert the transformed array back into a DataFrame,\n",
    "# you'll need to handle the column names and indices manually since\n",
    "# the output of ColumnTransformer is a numpy array.\n",
    "columns = numerical_columns + categorical_columns  # Adjust if necessary\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=columns, index=X.index)\n",
    "\n",
    "####################################################################################################\n",
    "# Assuming 'other_columns' is a list of the names of the untouched columns\n",
    "other_columns_data = df[other_columns]\n",
    "\n",
    "# Concatenate the untouched columns with the transformed DataFrame\n",
    "final_df = pd.concat([X_transformed_df, other_columns_data], axis=1)\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4eb528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling\n",
    "\n",
    "# 1) Scale the Whole Data Set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform both training and test data\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert arrays back to DataFrames, if necessary, to retain column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# 2) Scale Only Continuous Features\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming 'continuous_features' is a list of the names of the continuous columns\n",
    "continuous_features = ['your', 'continuous', 'feature', 'names', 'here']\n",
    "\n",
    "# Initialize the ColumnTransformer to scale only continuous features\n",
    "ct = ColumnTransformer([\n",
    "    (\"scale\", StandardScaler(), continuous_features)\n",
    "], remainder='passthrough')  # 'passthrough' means other columns will not be transformed\n",
    "\n",
    "# Fit on training data\n",
    "ct.fit(X_train)\n",
    "\n",
    "# Transform both training and test data\n",
    "X_train_scaled = ct.transform(X_train)\n",
    "X_test_scaled = ct.transform(X_test)\n",
    "\n",
    "# If you need the result as a DataFrame, you'll need to handle column ordering manually:\n",
    "# The transformed DataFrame will have scaled continuous features first, followed by untouched features\n",
    "scaled_columns = continuous_features  # Scaled\n",
    "unscaled_columns = [col for col in X_train.columns if col not in continuous_features]  # Not scaled\n",
    "all_columns = scaled_columns + unscaled_columns  # Combined column order\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=all_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=all_columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ffc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding\n",
    "\n",
    "# 1) Applying OneHotEncoder to Categorical Features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Assuming categorical_features is your list of categorical column names\n",
    "categorical_features = ['your', 'categorical', 'feature', 'names', 'here']\n",
    "\n",
    "# Initialize the OneHotEncoder and ColumnTransformer\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')  # sparse=False means output will be a dense matrix\n",
    "column_transformer = ColumnTransformer(transformers=[\n",
    "    ('cat', onehot_encoder, categorical_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit on the training data and transform both training and test sets\n",
    "X_train_encoded = column_transformer.fit_transform(X_train)\n",
    "X_test_encoded = column_transformer.transform(X_test)\n",
    "\n",
    "# 2) Applying LabelEncoder to Categorical Features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Assuming the column name you want to encode is \"gender\"\n",
    "# Apply LabelEncoder to the \"gender\" column of the training set\n",
    "X_train['gender_encoded'] = label_encoder.fit_transform(X_train['gender'])\n",
    "\n",
    "# Apply the same encoder to the test set to ensure consistency\n",
    "X_test['gender_encoded'] = label_encoder.transform(X_test['gender'])\n",
    "\n",
    "# 3) Combining OneHotEncoder and LabelEncoder for Individual Columns\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# OneHotEncoder setup for \"gender\" column\n",
    "onehot_encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "gender_encoded = onehot_encoder.fit_transform(X_train[['gender']])\n",
    "\n",
    "# Assuming there is another categorical feature for LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "other_feature_encoded = label_encoder.fit_transform(X_train['other_feature'])\n",
    "\n",
    "# For OneHotEncoder, you need to convert the output back to a DataFrame if you want to concatenate it back\n",
    "gender_encoded_df = pd.DataFrame(gender_encoded, columns=onehot_encoder.get_feature_names_out(['gender']), index=X_train.index)\n",
    "\n",
    "# For LabelEncoder, you can directly assign the encoded column back to the DataFrame\n",
    "X_train['other_feature_encoded'] = other_feature_encoded\n",
    "\n",
    "# Concatenate the OneHotEncoded column back to the original DataFrame (or a copy of it)\n",
    "X_train_processed = pd.concat([X_train, gender_encoded_df], axis=1)\n",
    "\n",
    "# Repeat similar steps for X_test, using transform() instead of fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "# 1) Logistic Regression\n",
    "# Initialize and fit the model\n",
    "lr_model = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]  # For AUC calculation\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy_lr}, AUC: {auc_lr}, F1 Score: {f1_lr}\")\n",
    "\n",
    "# 2) XGBoost Classifier\n",
    "# Initialize and fit the model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Classifier - Accuracy: {accuracy_xgb}, AUC: {auc_xgb}, F1 Score: {f1_xgb}\")\n",
    "\n",
    "# 3) K-Nearest Neighbors (KNN) Classifier\n",
    "# Initialize and fit the model\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "auc_knn = roc_auc_score(y_test, y_pred_proba_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "\n",
    "print(f\"KNN - Accuracy: {accuracy_knn}, AUC: {auc_knn}, F1 Score: {f1_knn}\")\n",
    "\n",
    "# 4) Random Forest Classifier\n",
    "# Initialize and fit the model\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, AUC: {auc_rf}, F1 Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'penalty': ['l2'],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=LogisticRegression(max_iter=1000),\n",
    "    param_grid=grid_lr,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs_lr.fit(X_train, y_train)\n",
    "\n",
    "best_params_lr = gs_lr.best_params_\n",
    "print(\"Best parameters for Logistic Regression:\", best_params_lr)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_lr = LogisticRegression(**best_params_lr)\n",
    "best_lr.fit(X_train, y_train)\n",
    "pred_lr = best_lr.predict(X_test)\n",
    "pred_proba_lr = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_lr = accuracy_score(y_test, pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, pred_proba_lr)\n",
    "f1_lr = f1_score(y_test, pred_lr)\n",
    "\n",
    "print(f\"Logistic Regression - Accuracy: {accuracy_lr}, AUC: {auc_lr}, F1 Score: {f1_lr}\")\n",
    "\n",
    "# XGBoost Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_grid=grid_xgb,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs_xgb.fit(X_train, y_train)\n",
    "\n",
    "best_params_xgb = gs_xgb.best_params_\n",
    "print(\"Best parameters for XGBoost Classifier:\", best_params_xgb)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_xgb = XGBClassifier(**best_params_xgb)\n",
    "best_xgb.fit(X_train, y_train)\n",
    "pred_xgb = best_xgb.predict(X_test)\n",
    "pred_proba_xgb = best_xgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, pred_proba_xgb)\n",
    "f1_xgb = f1_score(y_test, pred_xgb)\n",
    "\n",
    "print(f\"XGBoost Classifier - Accuracy: {accuracy_xgb}, AUC: {auc_xgb}, F1 Score: {f1_xgb}\")\n",
    "\n",
    "# KNN Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=grid_rf,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "best_params_rf = gs_rf.best_params_\n",
    "print(\"Best parameters for Random Forest:\", best_params_rf)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_rf = RandomForestClassifier(**best_params_rf)\n",
    "best_rf.fit(X_train, y_train)\n",
    "pred_rf = best_rf.predict(X_test)\n",
    "pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, pred_proba_rf)\n",
    "f1_rf = f1_score(y_test, pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, AUC: {auc_rf}, F1 Score: {f1_rf}\")\n",
    "\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=grid_rf,\n",
    "    scoring='f1',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "best_params_rf = gs_rf.best_params_\n",
    "print(\"Best parameters for Random Forest:\", best_params_rf)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_rf = RandomForestClassifier(**best_params_rf)\n",
    "best_rf.fit(X_train, y_train)\n",
    "pred_rf = best_rf.predict(X_test)\n",
    "pred_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, pred_proba_rf)\n",
    "f1_rf = f1_score(y_test, pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Accuracy: {accuracy_rf}, AUC: {auc_rf}, F1 Score: {f1_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb833f",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dee86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize and fit the Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(f\"Linear Regression - MSE: {mse_lr}, R2: {r2_lr}\")\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "########################################################################################################################\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for alpha\n",
    "grid_ridge = {'alpha': [0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize the GridSearchCV object\n",
    "gs_ridge = GridSearchCV(\n",
    "    estimator=Ridge(),\n",
    "    param_grid=grid_ridge,\n",
    "    scoring='neg_mean_squared_error',  # You might choose a different scorer depending on your objective\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "\n",
    "# Find the best parameters and evaluate on the test set\n",
    "best_params_ridge = gs_ridge.best_params_\n",
    "print(\"Best parameters for Ridge Regression:\", best_params_ridge)\n",
    "\n",
    "best_ridge = Ridge(**best_params_ridge)\n",
    "best_ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = best_ridge.predict(X_test)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"Ridge Regression - MSE: {mse_ridge}, R2: {r2_ridge}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbe57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "grid_xgb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "gs_xgb = GridSearchCV(\n",
    "    estimator=XGBRegressor(eval_metric='rmse'),\n",
    "    param_grid=grid_xgb,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d3b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor\n",
    "grid_knn = {\n",
    "    'n_neighbors': [5, 10, 15],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(\n",
    "    estimator=KNeighborsRegressor(),\n",
    "    param_grid=grid_knn,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb55331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "grid_rf = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(),\n",
    "    param_grid=grid_rf,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c171f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Assuming `best_model` is your trained regression model and X_test, y_test are your test datasets\n",
    "predictions = best_model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}, R2 Score: {r2}, Mean Absolute Error: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
